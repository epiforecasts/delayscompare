---
title: "plotoptions"
output: html_document
date: "2024-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
source(here("scripts", "01_packages.R"))
source(here("R", "funcs_plots.R"))
source(here("R", "funcs_data.R"))
source(here("R", "generate_scores_func.R"))
source(here("R", "lshtm_theme.R"))

# Make sure data lists are up-to-date
source(here("scripts","datacollect_ebola.R"))
source(here("scripts", "datacollect_cholera.R"))
source(here("scripts", "datacollect_covid.R"))
```

## Plot option 1
### Would be good to plot the CRPS contributions from over, underprediction, dispersion

```{r load and score, cache=TRUE}
# Loading all data and generating scores
disease <- "covid"

  ## Loading all data - collect Rt trajectories and simulated data in a list ##
  
  rt_traj <- read_latest(here("data"), paste0("rt_traj_list_", disease))
  sim_data <- read_latest(here("data"), paste0("sim_data_list_", disease))
  
  # Scenario labels
  scen_labs <- data.frame(scen=c(1:16),
                          rt_traj=c(rep("const_low", 4), rep("const_high", 4), rep("inc", 4), rep("dec", 4)),
                          rt_opts=rep(c("latest", "latest", "project", "project"), 4),
                          ur=rep(c("No under-reporting", "Under-reporting", "No under-reporting", "Under-reporting"), 4))
  
  scores_cases <- list()
  scores_rt <- list()
  
# Loading data

rt_traj_scen <- lapply(c(1:16), function(i){
  rt_traj[[i]] |> 
    as.data.frame() |> 
    mutate(scen=i)
})

sim_data_scen <- lapply(c(1:16), function(i){
  sim_data[[i]] |> 
    as.data.frame()|> 
    mutate(scen=i)
})


test_results <- lapply(c(1:16), function(i){
    
    ## Loading results & generating scores as we go in order to save memory ##
    res_samples <- read_latest(here(paste0("results/", disease)), paste0("res_", disease, "scen", i, "_all_samples"))
    res_R <- read_latest(here(paste0("results/", disease)), paste0("res_", disease, "scen", i, "_all_R"))
    res_id <- read_latest(here(paste0("results/", disease)), paste0("res_", disease, "scen", i, "_all_id")) 
    
    res_samples <- res_samples |> filter(date <= as.Date(startdate) + 6*4*7)
    res_R <- res_R |> filter(date <= as.Date(startdate) + 6*4*7)
    
    scores_cases <- generate_scores_cases(res_samples, res_id, sim_data_scen[[i]]) |> mutate(scen=i)
    scores_rt <- generate_scores_rt(res_R, res_id, rt_traj_scen[[i]]) |> mutate(scen=i)
    
    return(list(scores_cases,
                scores_rt))
    
  })

  rt_traj_scen <- bind_rows(rt_traj_scen)
  sim_data_scen <- bind_rows(sim_data_scen)
  
  scores_cases <- lapply(test_results, function(x) x[[1]]) |> bind_rows()
  scores_rt <- lapply(test_results, function(x) x[[2]]) |> bind_rows()
  
  # Add scenario labels
  rt_traj_scen <- rt_traj_scen |> 
    left_join(scen_labs, by="scen")
  
  sim_data_scen <- sim_data_scen |>
    left_join(scen_labs, by="scen")
  
  scores_cases <- scores_cases |>
    left_join(scen_labs, by="scen")
  
  scores_rt <- scores_rt |>
    left_join(scen_labs, by="scen")
```

## Bar chart showing the CRPS contributions from over, underprediction, dispersion - R

```{r barchart_r, echo=FALSE}
scores_rt_long <- scores_rt |>
  select(date, type, gen_time, inc_period, timepoint, scale, scen, rt_traj, rt_opts, ur, crps, overprediction, underprediction, dispersion) |>
  pivot_longer(cols=c("crps", "overprediction", "underprediction", "dispersion"), names_to="measure", values_to="value")

# Get the mean values across reporting assumptions, timepoints and GP methods

mean_scores_rt_gen_time <- scores_rt_long |>
  group_by(gen_time, rt_traj, measure) |>
  filter(inc_period=="correct") |>
  summarise(value=mean(value))

mean_scores_rt_inc_period <- scores_rt_long |>
  group_by(inc_period, rt_traj, measure) |>
  filter(gen_time=="correct") |>
  summarise(value=mean(value))

# Need to make gen_time and inc_period are factors so that ordering is correct:
mean_scores_rt_gen_time$gen_time <- factor(mean_scores_rt_gen_time$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

mean_scores_rt_inc_period$inc_period <- factor(mean_scores_rt_inc_period$inc_period, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

barchart_r_gen_time <- ggplot(mean_scores_rt_gen_time |> filter(measure!="crps")) + 
  geom_bar(aes(x=gen_time, y=value, fill=measure), stat="identity") +
  facet_wrap(~rt_traj) +
  xlab("Generation time") +
  ylab("CRPS") +
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1))

barchart_r_inc_period <- ggplot(mean_scores_rt_inc_period |> filter(measure!="crps")) +
  geom_bar(aes(x=inc_period, y=value, fill=measure), stat="identity") +
  facet_wrap(~rt_traj) +
  xlab("Incubation period") +
  ylab("CRPS") +
  lshtm_theme()  +
  theme(axis.text.x=element_text(angle=45, hjust=1))

legend <- get_legend(barchart_r_gen_time)

crps_rt <- plot_grid(barchart_r_gen_time + theme(legend.position="none"), barchart_r_inc_period + theme(legend.position="none"), legend, ncol=3, rel_widths=c(1, 1, 0.5))
ggsave(here("figures", "crps_rt.png"), crps_rt, width=10, height=5)

```

#### Notes

- The bar chart shows the contribution to the Rt CRPS from overprediction, underprediction and dispersion
- The left-hand plot shows the CRPS for different generation times, while the right-hand plot shows the CRPS for different incubation periods.
- The plots are faceted by the Rt trajectory used.
- For generation time, under and over prediction are the biggest contribution to the CRPS. When Rt is high (1.2), assuming a shorter generation time than the true gt leads to underprediction, while assuming a longer generation time leads to overprediction of Rt. Cases are increasing -> shorter gt -> lower Rt needed to compensate for larger number of generations in fixed time period.
- When Rt is constant and low (0.8), get more overprediction when gt assumed to be shorter, and more underprediction when gt assumed to be longer.
- When Rt is constant (low or high), the incubation period assumption makes no difference -> which tracks because incubation period just shifts Rt to the left or right, so will make no difference when Rt is constant. Dispersion is the biggest contribution to CRPS when generation time is kept correct, slightly more underprediction than over prediction.
- When Rt is decreasing over time, the biggest contribution to the CRPS is overprediction (makes sense) at all gt assumptions. The inverse is true when Rt is increasing over time.
- Under all Rt trajectories, dispersion increases when gt gets longer -> opposite to what I'd expect? As expect dispersion to be lower when Rt is lower. Longer generation time assumption will lead to lower Rt.

## Barchart showing the CRPS contributions from over, underprediction, dispersion - cases


```{r barchart_cases, echo=FALSE}
scores_cases_long <- scores_cases |>
  select(date, type, gen_time, inc_period, timepoint, scale, scen, rt_traj, rt_opts, ur, crps, overprediction, underprediction, dispersion) |>
  pivot_longer(cols=c("crps", "overprediction", "underprediction", "dispersion"), names_to="measure", values_to="value")

# Get the mean values across reporting assumptions, timepoints and GP methods

mean_scores_cases_gen_time <- scores_cases_long |>
  filter(inc_period=="correct") |>
  group_by(gen_time, rt_traj, measure) |>
  summarise(value=mean(value))

mean_scores_cases_inc_period <- scores_cases_long |>
  filter(gen_time=="correct") |>
  group_by(inc_period, rt_traj, measure) |>
  summarise(value=mean(value))

# Need to make gen_time a factor so that ordering is correct:
mean_scores_cases_gen_time$gen_time <- factor(mean_scores_cases_gen_time$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

mean_scores_cases_inc_period$inc_period <- factor(mean_scores_cases_inc_period$inc_period, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

barchart_cases_gen_time <- ggplot(mean_scores_cases_gen_time |> filter(measure!="crps")) + 
  geom_bar(aes(x=gen_time, y=value, fill=measure), stat="identity") +
  facet_wrap(~rt_traj) +
  xlab("Generation time") +
  ylab("CRPS") +
  lshtm_theme()  +
  theme(axis.text.x=element_text(angle=45, hjust=1))

barchart_cases_inc_period <- ggplot(mean_scores_cases_inc_period |> filter(measure!="crps")) +
  geom_bar(aes(x=inc_period, y=value, fill=measure), stat="identity") +
  facet_wrap(~rt_traj) +
  xlab("Incubation period") +
  ylab("CRPS") +
  lshtm_theme()  +
  theme(axis.text.x=element_text(angle=45, hjust=1))

legend <- get_legend(barchart_cases_gen_time)

crps_cases <- plot_grid(barchart_cases_gen_time + theme(legend.position="none"), barchart_cases_inc_period + theme(legend.position="none"), legend, ncol=3, rel_widths=c(1, 1, 0.5))

ggsave(here("figures", "crps_cases.png"), crps_cases, width=10, height=5)

```

#### Notes:

- Very little difference in CRPS across generation time and incubation period assumptions.
- Lower CRPS when const high Rt vs const low Rt (not sure that these are comparable though)
- When Rt is constant (low or high), dispersion and underprediction contribute most to CRPS. 
- When Rt is decreasing, see more overprediction of cases, whereas more underprediction when Rt is increasing.

## Barchart showing relative skill scores

```{r barchart_skill, echo=FALSE}
## Adding relative skill score

scores_cases_gen_time <- scores_cases |> filter(inc_period=="correct")

scores_cases_rel <- add_relative_skill(scores_cases_gen_time,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="crps",
                   baseline="correct")

scores_cases_rel <- add_relative_skill(scores_cases_rel,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="dispersion",
                   baseline="correct")

scores_cases_rel <- add_relative_skill(scores_cases_rel,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="overprediction",
                   baseline="correct")

scores_cases_rel <- add_relative_skill(scores_cases_rel,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="underprediction",
                   baseline="correct")

## Need to factor gen_time to ensure ordering is correct
scores_cases_rel$gen_time <- factor(scores_cases_rel$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

ggplot(scores_cases_rel, aes(x = factor(gen_time), y = crps_scaled_relative_skill - 1, fill = crps_scaled_relative_skill > 1)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ rt_traj, scales = "free") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  labs(
    x = "Generation time",
    y = "Relative skill",
    title = "Relative skill by generation time"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("TRUE" = "steelblue", "FALSE" = "salmon")) +
  theme(legend.position = "none")
```
```{r barchart_skill_rt}
## Adding relative skill score
scores_rt_gen_time <- scores_rt |> filter(inc_period=="correct")

scores_rt_rel <- add_relative_skill(scores_rt_gen_time,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="crps",
                   baseline="correct")

scores_rt_rel <- add_relative_skill(scores_rt_rel,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="dispersion",
                   baseline="correct")

scores_rt_rel <- add_relative_skill(scores_rt_rel,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="overprediction",
                   baseline="correct")

scores_rt_rel <- add_relative_skill(scores_rt_rel,
                   compare="gen_time",
                   by=c("rt_traj"),
                   metric="underprediction",
                   baseline="correct")

## Need to factor gen_time to ensure ordering is correct
scores_rt_rel$gen_time <- factor(scores_rt_rel$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

rel_plot_crps <- ggplot(scores_rt_rel, aes(x = factor(gen_time), y = crps_scaled_relative_skill - 1, fill = crps_scaled_relative_skill > 1)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ rt_traj, scales = "free", nrow=1) +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  labs(
    x = "Generation time",
    y = "Relative skill",
    title = "CRPS relative to correct generation time"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("TRUE" = "steelblue", "FALSE" = "salmon")) +
  theme(legend.position = "none", plot.title = element_text(size = 10),
        axis.text.x=element_text(angle=45, hjust=1, size=10),
        axis.text.y=element_text(size=10))

rel_plot_overprediction <- ggplot(scores_rt_rel, aes(x = factor(gen_time), y = overprediction_scaled_relative_skill - 1, fill = overprediction_scaled_relative_skill > 1)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ rt_traj, scales = "free", nrow=1) +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  labs(
    x = "Generation time",
    y = "Relative skill",
    title = "Overprediction relative to correct generation time"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("TRUE" = "steelblue", "FALSE" = "salmon")) +
  theme(legend.position = "none", plot.title = element_text(size = 10),
        axis.text.x=element_text(angle=45, hjust=1, size=10),
        axis.text.y=element_text(size=10))


rel_plot_underprediction <- ggplot(scores_rt_rel, aes(x = factor(gen_time), y = underprediction_scaled_relative_skill - 1, fill = underprediction_scaled_relative_skill > 1)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ rt_traj, scales = "free", nrow=1) +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  labs(
    x = "Generation time",
    y = "Relative skill",
    title = "Underprediction relative to correct generation time"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("TRUE" = "steelblue", "FALSE" = "salmon")) +
  theme(legend.position = "none", plot.title = element_text(size = 10),
        axis.text.x=element_text(angle=45, hjust=1, size=10),
        axis.text.y=element_text(size=10))


rel_plot_dispersion <- ggplot(scores_rt_rel, aes(x = factor(gen_time), y = dispersion_scaled_relative_skill - 1, fill = dispersion_scaled_relative_skill > 1)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ rt_traj, scales = "free", nrow=1) +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  labs(
    x = "Generation time",
    y = "Relative skill",
    title = "Dispersion relative to correct generation time"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("TRUE" = "steelblue", "FALSE" = "salmon")) +
  theme(legend.position = "none", plot.title = element_text(size = 10),
        axis.text.x=element_text(angle=45, hjust=1, size=10),
        axis.text.y=element_text(size=10))

plot_grid(rel_plot_crps, rel_plot_overprediction, rel_plot_underprediction, rel_plot_dispersion, ncol=1)

```

#### Notes:

Getting inf and NaN results. Maybe using add_relative_skill is overkill when can just calculate ratios directly

```{r ratios, fig.width=8, fig.height=8}

scores_rt_gen_time <- scores_rt |> filter(inc_period=="correct")

## Mean scores by Rt trajectory and generation time assumption
scores_rt_gen_time <- scores_rt_gen_time |> group_by(rt_traj, gen_time) |> summarise(across(c(crps, overprediction, underprediction, dispersion), mean))

baseline <- scores_rt_gen_time |> filter(gen_time=="correct")

scores_rt_gen_time <- scores_rt_gen_time |> 
  left_join(baseline, by="rt_traj", suffix=c("", "_baseline")) |> 
  mutate(crps_ratio=crps/crps_baseline,
         overprediction_ratio=overprediction/overprediction_baseline,
         underprediction_ratio=underprediction/underprediction_baseline,
         dispersion_ratio=dispersion/dispersion_baseline)

## Get rid of the NaNs - know these will occur in over/underprediction is 0 at baseline, when 0/0.

scores_rt_gen_time <- scores_rt_gen_time |> mutate(across(ends_with("ratio"), ~ifelse(is.nan(.), 1, .)))

## Maybe makes more sense to just not plot overprediction ratio for Rt_traj=increasing, given that 0 at baseline? Otherwise what to do with infs?

scores_rt_gen_time$gen_time <- factor(scores_rt_gen_time$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

  rel_plot_crps <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=crps_ratio - 1, fill = crps_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~rt_traj, scale="free", nrow=1) +
  xlab("Generation time") +
  ylab("CRPS ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")
  
 rel_plot_disp <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=dispersion_ratio - 1, fill = dispersion_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~rt_traj, scale="free", nrow=1) +
  xlab("Generation time") +
  ylab("Dispersion ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")
  
  rel_plot_overpredict <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=overprediction_ratio - 1, fill = overprediction_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~rt_traj, scale="free", nrow=1) +
  xlab("Generation time") +
  ylab("Overprediction ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")
  
  rel_plot_underpredict <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=underprediction_ratio - 1, fill = underprediction_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~rt_traj, scale="free", nrow=1) +
  xlab("Generation time") +
  ylab("Underprediction ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")
  
  plot_grid(rel_plot_crps, rel_plot_disp, rel_plot_overpredict, rel_plot_underpredict, ncol=1)

```

#### Notes:

- Need to work out why dispersion results are opposite to expected.
- Longer gt -> smaller Rt.
- Going to split the results by rt_opts to see if the results are then clearer.

```{r rt_opts_plot_crps}

scores_rt_gen_time <- scores_rt |> filter(inc_period=="correct")

## Mean scores by Rt trajectory and generation time assumption
scores_rt_gen_time <- scores_rt_gen_time |> group_by(rt_traj, gen_time, rt_opts) |> summarise(across(c(crps, overprediction, underprediction, dispersion), mean))

baseline <- scores_rt_gen_time |> filter(gen_time=="correct")

scores_rt_gen_time <- scores_rt_gen_time |> 
  left_join(baseline, by=c("rt_traj", "rt_opts"), suffix=c("", "_baseline")) |> 
  mutate(crps_ratio=crps/crps_baseline,
         overprediction_ratio=overprediction/overprediction_baseline,
         underprediction_ratio=underprediction/underprediction_baseline,
         dispersion_ratio=dispersion/dispersion_baseline)

## Get rid of the NaNs - know these will occur in over/underprediction is 0 at baseline, when 0/0.

scores_rt_gen_time <- scores_rt_gen_time |> mutate(across(ends_with("ratio"), ~ifelse(is.nan(.), 1, .)))

## Maybe makes more sense to just not plot overprediction ratio for Rt_traj=increasing, given that 0 at baseline? Otherwise what to do with infs?

scores_rt_gen_time$gen_time <- factor(scores_rt_gen_time$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

  rel_plot_crps <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=crps_ratio - 1, fill = crps_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("CRPS ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")
  
  print(rel_plot_crps)
```
#### Notes:
- When Rt is constant (low or high) correct performs best on the whole.
- Less stark differences when Rt is increasing/decreaing but still low/correct performing the best.

```{r rt_opts_plot_overpredict }

  rel_plot_overpredict <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=overprediction_ratio - 1, fill = overprediction_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Overprediction ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

abs_plot_overpredict <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=overprediction, fill = overprediction)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj, scales="free") +
  xlab("Generation time") +
  ylab("Overprediction") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

print(abs_plot_overpredict)
```

#### Notes:

- More overprediction with project than latest at longer generation times when Rt is constant and high.
- Longer generation time -> current cases more heavily dependent on earlier timepoints when cases were lower -> so need higher Rt than true Rt to fit to cases. In other words, longer generation time -> fewer generations can occur -> need higher Rt to fit given rate of epidemic growth.
- Results concur with Gostic et al. 2020: "mean generation interval too high -> Rt values will be further from 1 (too high when Rt>1, too low when Rt<1). When mean generation interval is too low -> estimated Rt is closer to 1 than true Rt - so more overprediction when Rt<1 and more underprediction when Rt>1."

- Latest -> Rt will remain high but the same when forecasting into the future. Project -> Rt has the potential to get higher -> so would expect more overprediction from "project" option at longer generation times.
- When Rt is low and constant -> cases are decreasing. Shorter generation time -> Rt more heavily dependent on too few cases -> leading to higher Rt than true Rt. When rt_opts=latest, this higher Rt will be maintained into the future, leading to overprediction. When rt_opts=project, the Rt will be allowed to decrease, leading to less overprediction.
- When Rt is decreasing: goes from 1.2 to 0.8 so effect of Rt>1 and Rt<1 cancel out? Might expect that when rt_opts=latest, that would lead to some overprediction? Both project and latest have slight overprediction at no delay/short gt but not much compared to effect on other Rt trajectory scenarios.
- When Rt is increasing -> no overprediction so ratios don't make sense (/0).
- Why would there by no overprediction when Rt is increasing? Might expect some with project?

```{r rt_opts_plot_underpredict }
  
  rel_plot_underpredict <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=underprediction_ratio - 1, fill = underprediction_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Underprediction ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

  abs_plot_underpredict <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=underprediction, fill = underprediction)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Underprediction") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")
  
print(abs_plot_underpredict)
```

#### Notes:

- As predicted, see reverse of overprediction for constant low Rt and constant high Rt. 
- For constant high Rt -> cases are increasing -> shorter generation time means cases dependent on higher number of recent cases -> need lower Rt to fit to cases -> leading to more underprediction.
- Underprediction is higher for rt_opts=project vs. rt_opt=latest, when Rt is allowed to decrease into the future.
- When at constant low Rt, see more underprediction when generation times are longer -> cases estimated using earlier higher number of cases -> need lower Rt to fit to cases -> leading to more underprediction.
- At no delay/very low/low -> there is actually less underprediction compared to correct gt. More likely to overpredict than underpredict when generation time is very short -> because cases are dependent on most recent timepoints when cases were lower.
- When Rt is decreasing -> see more underprediction at the extremes -> again difficult to interrupt these results as cases are both rising and falling throughout.
- Underprediction is low when Rt is increasing.

```{r rt_opts_plot_disp }

rel_plot_disp <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=dispersion_ratio - 1, fill = dispersion_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Dispersion ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

## Plotting absolute values rather than ratios
abs_plot_disp <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=dispersion, fill=dispersion)) +
  geom_bar(stat="identity") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Dispersion") +
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

print(rel_plot_disp)
print(abs_plot_disp)
```

#### Notes:
- Dispersion is always lower at lower generation times, regardless of Rt trajectory or GP. 
- This makes sense for shorter generation times when Rt is high -> shorter generation time -> lower Rt -> less dispersion.
- But when Rt is low and so cases are decreasing -> shorter generation time means higher Rt (maybe this doesn't make sense and I have confused myself during the under/overprediction interpretation?) No, it is the case that underprediction is higher for longer generation times when Rt is low. In which case, would expect lower Rts and less dispersion.
- Seems to be higher for latest compared to project - which is the opposite to what I expected?? - this was because I was looking at relative values.

#### Update:

- When looking at the absolute values, dispersion is higher for project vs. latest.
- Still can't make sense of the higher dispersion at higher generation times all the time -> need to look at the timeseries to make sense of this.


## For cases:

```{r cases_opts_plot_overpredict }

scores_cases_gen_time <- scores_cases |> filter(inc_period=="correct")

## Mean scores by Rt trajectory and generation time assumption
scores_cases_gen_time <- scores_cases_gen_time |> group_by(rt_traj, gen_time, rt_opts) |> summarise(across(c(crps, overprediction, underprediction, dispersion), mean))

baseline <- scores_cases_gen_time |> filter(gen_time=="correct")

scores_cases_gen_time <- scores_cases_gen_time |> 
  left_join(baseline, by=c("rt_traj", "rt_opts"), suffix=c("", "_baseline")) |> 
  mutate(crps_ratio=crps/crps_baseline,
         overprediction_ratio=overprediction/overprediction_baseline,
         underprediction_ratio=underprediction/underprediction_baseline,
         dispersion_ratio=dispersion/dispersion_baseline)

## Get rid of the NaNs - know these will occur in over/underprediction is 0 at baseline, when 0/0.

scores_cases_gen_time <- scores_cases_gen_time |> mutate(across(ends_with("ratio"), ~ifelse(is.nan(.), 1, .)))

## Maybe makes more sense to just not plot overprediction ratio for Rt_traj=increasing, given that 0 at baseline? Otherwise what to do with infs?

scores_cases_gen_time$gen_time <- factor(scores_cases_gen_time$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

  rel_plot_overpredict <- ggplot(scores_cases_gen_time, aes(x=gen_time, y=overprediction_ratio - 1, fill = overprediction_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Overprediction ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

print(rel_plot_overpredict)
```

#### Notes:

- Smaller + more inconsistent differences across generation time assumptions. Conclusion = that correct generation time is important for Rt calculation but can be compensated for when forecasting cases?
- Think about inc/dec contrasting results.
- Need to compare different forecasting horizons to see if gets worse over time? But this is already 2 weeks ahead.

```{r cases_opts_plot_underpredict}

  rel_plot_underpredict <- ggplot(scores_cases_gen_time, aes(x=gen_time, y=underprediction_ratio - 1, fill = underprediction_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Underprediction ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

plot(rel_plot_underpredict)

```

#### Notes:

- Very high gt -> higher underprediction, much less overprediction. Overprediction is worse for project than latest.
```{r cases_opts_plot_disp}

rel_plot_disp <- ggplot(scores_cases_gen_time, aes(x=gen_time, y=dispersion_ratio - 1, fill = dispersion_ratio > 1)) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Dispersion ratio") +
  scale_y_continuous(labels = function(x) x + 1) + # Relabel to show actual scores centered around 1
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

plot(rel_plot_disp)

```

#### Notes:

- Dispersion has a more consistent pattern -> more dispersion at the extremes. Again -> slightly lower when using project? Opposite to expected.

#### In summary:

- Underprediction is low then Rt is increasing; overprediction is low when Rt is decreasing (as might expect).
- If Rt is less than 1: get more overprediction at shorter generation times, more underprediction at longer generation times.
- If Rt is greater than 1: get more underprediction at shorter generation times, more overprediction at longer generation times.
- Over the course of an outbreak -> these effects cancel out and the best-performing overall (in terms of forecasting Rt) = correct specification.

## Dispersion plots ##

```{r dispersion_plots}

disease <- "ebola"
res_R_list <- lapply(c(1:16), function(i){
#res_samples <- read_latest(here(paste0("results/", disease, "/", disease)), paste0("res_", disease, "scen", i, "_all_samples"))
res_R <- read_latest(here(paste0("results/", disease, "/", disease)), paste0("res_", disease, "scen", i, "_all_R"))
res_id <- read_latest(here(paste0("results/", disease, "/",  disease)), paste0("res_", disease, "scen", i, "_all_id")) 

# Need to add result_list to res_id
  res_id <- res_id |> 
    group_by(gt) |>
    mutate(result_list=1:n())
  
  # Add info to res_R
res_R <- res_R |>
  left_join(res_id, by=c("result_list", "gt"))

res_R <- res_R |>
  filter(type=="forecast")

# Just keeping quantiles
res_R <- res_R |> group_by(date, timepoint, gen_time, inc_period) |>
  summarise(lower90=quantile(value, 0.05),
            upper90=quantile(value, 0.95),
            lower50=quantile(value, 0.25),
            upper50=quantile(value, 0.75),
            median=quantile(value, 0.5)) |>
  mutate(scen=i)

return(res_R)})

scen_labs <- data.frame(scen=c(1:16),
                          rt_traj=c(rep("const_low", 4), rep("const_high", 4), rep("inc", 4), rep("dec", 4)),
                          rt_opts=rep(c("latest", "latest", "project", "project"), 4),
                          ur=rep(c("No under-reporting", "Under-reporting", "No under-reporting", "Under-reporting"), 4))

# Bind rows #
res_R <- bind_rows(res_R_list) |>
  left_join(scen_labs, by="scen")

## Attach true values ##
rt_traj <- read_latest(here("data"), paste0("rt_traj_list_", disease))
rt_traj_scen <- lapply(c(1:16), function(i){
  rt_traj[[i]] |> 
    as.data.frame() |> 
    mutate(scen=i)
})

rt_traj_scen <- bind_rows(rt_traj_scen)

res_R <- res_R |>
  left_join(rt_traj_scen, by=c("date", "scen"))

## Comparing dispersion under different Rt opts assumptions
res_R_test <- res_R |> filter(ur=="No under-reporting", rt_traj=="inc")

res_R_test$gen_time <- factor(res_R_test$gen_time, levels=c("no delay", "very low", "low", "correct", "high", "very high"))
res_R_gentime <- res_R_test |> filter(inc_period=="correct")

forecasts_gentime <- ggplot() + geom_line(res_R_gentime, mapping=aes(x=date, y=R)) 

    for(i in 1:max(res_R_gentime$timepoint)){
      forecasts_gentime <- forecasts_gentime + 
        geom_line(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, y=median, color=gen_time)) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower50, ymax=upper50, fill=gen_time), alpha=0.5) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower90, ymax=upper90, fill=gen_time), alpha=0.2)
    }
    # Aesthetics
    forecasts_gentime <- forecasts_gentime + 
      scale_fill_viridis(discrete=TRUE, name="Generation time") +
      scale_colour_viridis(discrete=TRUE, name="Generation time") +
      xlab("Date") +
      ylab("Estimated Rt") +
      facet_grid(gen_time~rt_opts) +
      lshtm_theme() +
      ylim(0, max(res_R_gentime$upper90))
    
    plot(forecasts_gentime)
    
```

#### Notes:

- Can see clearly from the plot that dispersion is higher when using "project" rather than "latest. Can also see that dispersion is higher when using longer generation times.
- Longer generation time -> need higher Rt to fit to cases -> more dispersion.
- But this explanation doesn't make sense if there is also higher dispersion when Rt is decreasing -> lets look at that plot next.

```{r dispersion_plot_rt}
res_R_dec <- res_R |> filter(ur=="No under-reporting", rt_traj=="dec")

res_R_dec$gen_time <- factor(res_R_dec$gen_time, levels=c("no delay", "very low", "low", "correct", "high", "very high"))
res_R_gentime <- res_R_dec |> filter(inc_period=="correct")

forecasts_gentime <- ggplot() + geom_line(res_R_gentime, mapping=aes(x=date, y=R)) 

    for(i in 1:max(res_R_gentime$timepoint)){
      forecasts_gentime <- forecasts_gentime + 
        geom_line(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, y=median, color=gen_time)) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower50, ymax=upper50, fill=gen_time), alpha=0.5) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower90, ymax=upper90, fill=gen_time), alpha=0.2)
    }
    # Aesthetics
    forecasts_gentime <- forecasts_gentime + 
      scale_fill_viridis(discrete=TRUE, name="Generation time") +
      scale_colour_viridis(discrete=TRUE, name="Generation time") +
      xlab("Date") +
      ylab("Estimated Rt") +
      facet_grid(gen_time~rt_opts) +
      lshtm_theme() +
      ylim(0, max(res_R_gentime$upper90))
    
    plot(forecasts_gentime)
    
```

#### Notes:

- Can see how under and overprediction patterns change when Rt crosses 1.
- Maybe I should take out the first timepoint, because there seems to be higher under/overprediction and dispersion there, which could be skewing the rest of the results.
- Need to look and high and low Rt separately.

```{r dispersion_plot_rt_high}
res_R_high <- res_R |> filter(ur=="No under-reporting", rt_traj=="const_high")

res_R_high$gen_time <- factor(res_R_high$gen_time, levels=c("no delay", "very low", "low", "correct", "high", "very high"))
res_R_gentime <- res_R_high |> filter(inc_period=="correct")

forecasts_gentime_high <- ggplot() + geom_line(res_R_gentime, mapping=aes(x=date, y=R)) 

    for(i in 1:max(res_R_gentime$timepoint)){
      forecasts_gentime_high <- forecasts_gentime_high + 
        geom_line(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, y=median, color=gen_time)) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower50, ymax=upper50, fill=gen_time), alpha=0.5) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower90, ymax=upper90, fill=gen_time), alpha=0.2)
    }
    # Aesthetics
    forecasts_gentime_high <- forecasts_gentime_high + 
      scale_fill_viridis(discrete=TRUE, name="Generation time") +
      scale_colour_viridis(discrete=TRUE, name="Generation time") +
      xlab("Date") +
      ylab("Estimated Rt") +
      facet_grid(gen_time~rt_opts) +
      lshtm_theme() +
      ylim(0, max(res_R_gentime$upper90)) +
      theme(legend.position="none")
    
## Low
    
    res_R_low <- res_R |> filter(ur=="No under-reporting", rt_traj=="const_low")

res_R_low$gen_time <- factor(res_R_low$gen_time, levels=c("no delay", "very low", "low", "correct", "high", "very high"))
res_R_gentime <- res_R_low |> filter(inc_period=="correct")

forecasts_gentime_low <- ggplot() + geom_line(res_R_gentime, mapping=aes(x=date, y=R)) 

    for(i in 1:max(res_R_gentime$timepoint)){
      forecasts_gentime_low <- forecasts_gentime_low + 
        geom_line(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, y=median, color=gen_time)) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower50, ymax=upper50, fill=gen_time), alpha=0.5) +
        geom_ribbon(res_R_gentime |> filter(timepoint==i | is.na(timepoint)), mapping=aes(x=date, ymin=lower90, ymax=upper90, fill=gen_time), alpha=0.2)
    }
    # Aesthetics
    forecasts_gentime_low <- forecasts_gentime_low + 
      scale_fill_viridis(discrete=TRUE, name="Generation time") +
      scale_colour_viridis(discrete=TRUE, name="Generation time") +
      xlab("Date") +
      ylab("Estimated Rt") +
      facet_grid(gen_time~rt_opts) +
      lshtm_theme() +
      ylim(0, max(res_R_gentime$upper90))
    
    legend <- get_legend(forecasts_gentime_low)
    
    plot_grid(forecasts_gentime_high, forecasts_gentime_low + theme(legend.position="none"), legend, ncol=3, rel_widths=c(1,1,0.4))
    
    
```

 - Can clearly see the over/underprediction trends. Dispersion is clearly greater for higher gt regardless of Rt value. 
 - When Rt is 0.8, higher values predicted when no delay/very low delay, but dispersion is still higher when gt is longer.
 - Need to check if it really has that much of an effect once first timepoint is gone
 
```{r rm_first_timepoint}
scores_rt_gen_time <- scores_rt |> filter(inc_period=="correct")

## Remove first timepoint
scores_rt_gen_time <- scores_rt_gen_time |> filter(timepoint!=1)
## Mean scores by Rt trajectory and generation time assumption
scores_rt_gen_time <- scores_rt_gen_time |> group_by(rt_traj, gen_time, rt_opts) |> summarise(across(c(crps, overprediction, underprediction, dispersion), mean))

scores_rt_gen_time$gen_time <- factor(scores_rt_gen_time$gen_time, levels=c("no delay",
                                                                                      "very low",
                                                                                      "low",
                                                                                      "correct",
                                                                                      "high",
                                                                                      "very high"))

 ## Plotting absolute values rather than ratios
abs_plot_disp <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=dispersion, fill=dispersion)) +
  geom_bar(stat="identity") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("Dispersion") +
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

print(abs_plot_disp)
```

#### Notes:

- Still has same pattern of more dispersion at longer generation times.

```{r}
abs_plot_crps <- ggplot(scores_rt_gen_time, aes(x=gen_time, y=crps, fill=crps)) +
  geom_bar(stat="identity") +
  facet_grid(rt_opts~rt_traj) +
  xlab("Generation time") +
  ylab("CRPS") +
  lshtm_theme() +
  theme(axis.text.x=element_text(angle=45, hjust=1), legend.position="none")

print(abs_plot_crps)
```


 


 